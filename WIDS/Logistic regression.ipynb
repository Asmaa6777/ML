{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a443afe",
   "metadata": {},
   "source": [
    "# Logistic regression \n",
    "\n",
    "\n",
    "#### outperformed LGBM due to the linear nature of the relationships in the data, achieving better results on the private leaderboard : 0.79463 compared to the public leaderboard : 0.66145 .\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b789ecf6",
   "metadata": {},
   "source": [
    "This code builds a two-step machine learning pipeline using logistic regression with repeated stratified cross-validation to predict a childâ€™s sex and ADHD outcome. First, it trains a model to predict the probability of being female (Sex_F), then uses that prediction to create interaction features with other variables to improve the ADHD prediction. It handles imbalanced data by giving more weight to ADHD-positive samples and evaluates performance using F1 score and ROC-AUC across multiple folds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e05944",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82aaa9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import ndcg_score\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pathlib import Path\n",
    "from scipy.stats import hmean\n",
    "import scipy\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a92d2e2",
   "metadata": {},
   "source": [
    "### preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be44016",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "path = r'C:\\Users\\Family\\Downloads\\widsdatathon2025 (3)'\n",
    "\n",
    "def read_data(base_path:str) -> pd.DataFrame :\n",
    "    path = Path(base_path)\n",
    "    trc=pd.read_excel(path /'TRAIN_NEW'  / 'TRAIN_CATEGORICAL_METADATA_new.xlsx')\n",
    "    trq=pd.read_excel(path /'TRAIN_NEW'  / 'TRAIN_QUANTITATIVE_METADATA_new.xlsx')\n",
    "    trf=pd.read_csv(path   /'TRAIN_NEW'  / 'TRAIN_FUNCTIONAL_CONNECTOME_MATRICES_new_36P_Pearson.csv')\n",
    "    trs=pd.read_excel(path /'TRAIN_NEW'  / 'TRAINING_SOLUTIONS.xlsx')  \n",
    "    tsc=pd.read_excel(path /'TEST'      / 'TEST_CATEGORICAL.xlsx')\n",
    "    tsq=pd.read_excel(path /'TEST'       / 'TEST_QUANTITATIVE_METADATA.xlsx')    \n",
    "    tsf=pd.read_csv(path   /'TEST'       / 'TEST_FUNCTIONAL_CONNECTOME_MATRICES.csv')    \n",
    "    sub=pd.read_excel(path / 'SAMPLE_SUBMISSION.xlsx')    \n",
    "    dic=pd.read_excel(path /'Data Dictionary.xlsx')\n",
    "    return trc, trq, trf, trs, tsc, tsq, tsf, sub, dic\n",
    "\n",
    "trc, trq, trf, trs, tsc, tsq, tsf, sub, dic = read_data(base_path=path)\n",
    "\n",
    "# Data Merging \n",
    "cq = pd.merge(trc, trq, on='participant_id', how='left')\n",
    "feat = pd.merge(cq, trf, on='participant_id', how='left')  \n",
    "qc = pd.merge(tsc, tsq, on='participant_id', how='left')\n",
    "train = pd.merge(feat, trs, on='participant_id', how='left') \n",
    "test = pd.merge(qc, tsf, on='participant_id', how='left')\n",
    "train_sex =train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b192f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = train['participant_id']\n",
    "test_ids = test['participant_id'] # I will store them for later usage in grouping in validation why?  I don't want the same user to appear in both train and test. \n",
    "num_feats = trq # numerical features\n",
    "cat_feats = trc # seperate categorical and numerical features help me reteriving them later easily for preprocessing.\n",
    "target_cols = ['ADHD_Outcome', 'Sex_F']\n",
    "groups = train_ids\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "753cbc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.220e+00, tolerance: 4.923e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.402e+00, tolerance: 5.646e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.501e+00, tolerance: 9.479e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.220e+00, tolerance: 4.923e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.402e+00, tolerance: 5.646e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.501e+00, tolerance: 9.479e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.220e+00, tolerance: 4.923e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.402e+00, tolerance: 5.646e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.501e+00, tolerance: 9.479e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.220e+00, tolerance: 4.923e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.402e+00, tolerance: 5.646e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.501e+00, tolerance: 9.479e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.220e+00, tolerance: 4.923e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.402e+00, tolerance: 5.646e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.501e+00, tolerance: 9.479e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\impute\\_iterative.py:895: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.138e+00, tolerance: 1.063e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.191e-01, tolerance: 1.249e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.220e+00, tolerance: 2.173e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 57.705368523078505, tolerance: 54.62246194279837\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 63.64947708428372, tolerance: 54.62246194279837\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 70.45652162254555, tolerance: 54.62246194279837\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 78.25303920154693, tolerance: 54.62246194279837\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 87.18342166085495, tolerance: 54.62246194279837\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.138e+00, tolerance: 1.063e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.191e-01, tolerance: 1.249e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.220e+00, tolerance: 2.173e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 56.452079902461264, tolerance: 54.62246194279837\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 61.975659622461535, tolerance: 54.62246194279837\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 68.29784536501393, tolerance: 54.62246194279837\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 75.53646806970937, tolerance: 54.62246194279837\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.138e+00, tolerance: 1.063e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.191e-01, tolerance: 1.249e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.220e+00, tolerance: 2.173e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 59.38507271686103, tolerance: 54.62246194279837\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 65.38368596072542, tolerance: 54.62246194279837\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 72.25161778798793, tolerance: 54.62246194279837\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 80.1165836713626, tolerance: 54.62246194279837\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.138e+00, tolerance: 1.063e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.191e-01, tolerance: 1.249e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.220e+00, tolerance: 2.173e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 58.458702997420914, tolerance: 54.62246194279837\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 64.34644913248485, tolerance: 54.62246194279837\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 71.08736002753722, tolerance: 54.62246194279837\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 78.80683661869261, tolerance: 54.62246194279837\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.138e+00, tolerance: 1.063e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.191e-01, tolerance: 1.249e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.220e+00, tolerance: 2.173e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Train has 25 features/columns with missing values: ['PreInt_Demos_Fam_Child_Ethnicity', 'PreInt_Demos_Fam_Child_Race', 'MRI_Track_Scan_Location', 'Barratt_Barratt_P1_Edu', 'Barratt_Barratt_P1_Occ', 'Barratt_Barratt_P2_Edu', 'Barratt_Barratt_P2_Occ', 'EHQ_EHQ_Total', 'ColorVision_CV_Score', 'APQ_P_APQ_P_CP', 'APQ_P_APQ_P_ID', 'APQ_P_APQ_P_INV', 'APQ_P_APQ_P_OPD', 'APQ_P_APQ_P_PM', 'APQ_P_APQ_P_PP', 'SDQ_SDQ_Conduct_Problems', 'SDQ_SDQ_Difficulties_Total', 'SDQ_SDQ_Emotional_Problems', 'SDQ_SDQ_Externalizing', 'SDQ_SDQ_Generating_Impact', 'SDQ_SDQ_Hyperactivity', 'SDQ_SDQ_Internalizing', 'SDQ_SDQ_Peer_Problems', 'SDQ_SDQ_Prosocial', 'MRI_Track_Age_at_Scan']\n",
    "Test  has 23 features/columns with missing values: ['PreInt_Demos_Fam_Child_Ethnicity', 'PreInt_Demos_Fam_Child_Race', 'Barratt_Barratt_P1_Edu', 'Barratt_Barratt_P1_Occ', 'Barratt_Barratt_P2_Edu', 'Barratt_Barratt_P2_Occ', 'EHQ_EHQ_Total', 'ColorVision_CV_Score', 'APQ_P_APQ_P_CP', 'APQ_P_APQ_P_ID', 'APQ_P_APQ_P_INV', 'APQ_P_APQ_P_OPD', 'APQ_P_APQ_P_PM', 'APQ_P_APQ_P_PP', 'SDQ_SDQ_Conduct_Problems', 'SDQ_SDQ_Difficulties_Total', 'SDQ_SDQ_Emotional_Problems', 'SDQ_SDQ_Externalizing', 'SDQ_SDQ_Generating_Impact', 'SDQ_SDQ_Hyperactivity', 'SDQ_SDQ_Internalizing', 'SDQ_SDQ_Peer_Problems', 'SDQ_SDQ_Prosocial']\n",
    "fMRI has no missing values\n",
    "Extra columns in train: ['MRI_Track_Age_at_Scan', 'MRI_Track_Scan_Location']\n",
    "'''\n",
    "\n",
    "# Find columns with missing values only\n",
    "train_missing_features_to_impute = train.columns[train.isnull().any()].tolist() # List of features with missing values in train, only 25 and no missing data in fMRI data\n",
    "test_missing_features_to_impute = test.columns[test.isnull().any()].tolist() # List of features with missing values in test, only 23 and no missing data in fMRI data\n",
    "\n",
    "\n",
    "# Initialize the imputer\n",
    "imputer = IterativeImputer(estimator=LassoCV(random_state=42), max_iter=5, random_state=42)\n",
    "\n",
    "# Impute in-place for train\n",
    "if train_missing_features_to_impute:\n",
    "\ttrain[train_missing_features_to_impute] = imputer.fit_transform(train[train_missing_features_to_impute])\n",
    "\n",
    "# Impute in-place for test\n",
    "if test_missing_features_to_impute:\n",
    "\ttest[test_missing_features_to_impute] = imputer.fit_transform(test[test_missing_features_to_impute])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd45b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum().sum(), test.isnull().sum().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b830fbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# Only apply scaling to numerical columns that are not part of the target or categorical features\n",
    "numerical_features = [col for col in train.columns if col not in target_cols and col not in cat_feats]\n",
    "\n",
    "# Fit scaler on the numerical features of the train set and transform train and test sets\n",
    "train[numerical_features] = scaler.fit_transform(train[numerical_features])  # Fit and transform for train set\n",
    "test[numerical_features] = scaler.transform(test[numerical_features]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83eea20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sex = train['Sex_F']  \n",
    "y_adhd = train['ADHD_Outcome']  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2568f463",
   "metadata": {},
   "source": [
    "# feature importance in sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7fd07a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 416, number of negative: 797\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.603047 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5075431\n",
      "[LightGBM] [Info] Number of data points in the train set: 1213, number of used features: 19927\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "\n",
      "Number of important features for Sex: 2310\n",
      "\n",
      "Top 10 important features for Sex prediction:\n",
      "                    Feature  Importance\n",
      "19098  158throw_191thcolumn          21\n",
      "16356  114throw_199thcolumn          15\n",
      "13249   83throw_192thcolumn          14\n",
      "17753  133throw_171thcolumn          11\n",
      "18830  152throw_184thcolumn          10\n",
      "14901   99throw_124thcolumn          10\n",
      "19896  191throw_197thcolumn           9\n",
      "19321  164throw_189thcolumn           9\n",
      "7861     44throw_69thcolumn           8\n",
      "12304    76throw_80thcolumn           8\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming 'train' and 'test' are your DataFrames\n",
    "# and target_cols is defined as ['ADHD_Outcome', 'Sex_F']\n",
    "\n",
    "# Prepare features (X) - drop targets and participant_id\n",
    "X = train.drop(columns=target_cols + ['participant_id'])\n",
    "\n",
    "# Convert categorical features to dummy variables\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Encode target (y_sex should be your target Series)\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y_sex)\n",
    "\n",
    "# Initialize and fit the LGBM model for Sex prediction\n",
    "model_sex = lgb.LGBMClassifier(\n",
    "    class_weight='balanced',  # Important for imbalanced data\n",
    "    random_state=42\n",
    ")\n",
    "model_sex.fit(X, y)\n",
    "\n",
    "# Get feature importances and create a DataFrame\n",
    "importance_df_sex = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': model_sex.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "# Filter features with importance > 0 (or set a higher threshold)\n",
    "important_features_sex = importance_df_sex[importance_df_sex['Importance'] > 0]['Feature'].tolist()\n",
    "\n",
    "# Filter the data - ensure test has same features\n",
    "train_sex = train[important_features_sex]\n",
    "test_sex = test[important_features_sex]\n",
    "\n",
    "# Verify the filtered data\n",
    "print(f\"\\nNumber of important features for Sex: {len(important_features_sex)}\")\n",
    "print(\"\\nTop 10 important features for Sex prediction:\")\n",
    "print(importance_df_sex.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1088095c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop only the columns from `trf` that are present in `train`\n",
    "columns_to_drop = [col for col in trf.columns if col in test.columns]\n",
    "test_adhd = test.drop(columns=columns_to_drop)\n",
    "\n",
    "# Drop the target columns\n",
    "test_adhd = test_adhd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5f57d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop only the columns from `trf` that are present in `train`\n",
    "columns_to_drop = [col for col in trf.columns if col in train.columns]\n",
    "train_adhd = train.drop(columns=columns_to_drop)\n",
    "\n",
    "# Drop the target columns\n",
    "train_adhd = train_adhd.drop(columns=target_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497ea832",
   "metadata": {},
   "source": [
    "Important features of ADHD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e16017",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features_adhd = ['Basic_Demos_Enroll_Year', 'Barratt_Barratt_P1_Edu',\n",
    "       'Barratt_Barratt_P2_Edu', 'EHQ_EHQ_Total', 'ColorVision_CV_Score',\n",
    "       'APQ_P_APQ_P_CP', 'APQ_P_APQ_P_ID', 'APQ_P_APQ_P_INV',\n",
    "       'APQ_P_APQ_P_OPD', 'APQ_P_APQ_P_PM', 'APQ_P_APQ_P_PP',\n",
    "       'SDQ_SDQ_Conduct_Problems', 'SDQ_SDQ_Difficulties_Total',\n",
    "       'SDQ_SDQ_Emotional_Problems', 'SDQ_SDQ_Externalizing',\n",
    "       'SDQ_SDQ_Generating_Impact', 'SDQ_SDQ_Hyperactivity',\n",
    "       'SDQ_SDQ_Internalizing', 'SDQ_SDQ_Peer_Problems', 'SDQ_SDQ_Prosocial',\n",
    "       'MRI_Track_Age_at_Scan']\n",
    "\n",
    "# Features to be interacted with predicted probability of Sex_F = 1\n",
    "interactions = [\n",
    "    \"APQ_P_APQ_P_INV\", \"APQ_P_APQ_P_PP\", \"SDQ_SDQ_Hyperactivity\",\n",
    "    \"MRI_Track_Age_at_Scan\", \"SDQ_SDQ_Generating_Impact\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de325da0",
   "metadata": {},
   "source": [
    "thersholed uesed here to solve the imblanased data problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1e3e9a",
   "metadata": {},
   "source": [
    "# ADHD and SEX using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa6a1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1 ===\n",
      "Sex_F -> F1: 0.5139, ROC-AUC: 0.6287\n",
      "Sex_F -> F1: 0.5139, ROC-AUC: 0.6287\n",
      "Outcome ADHD -> F1: 0.8146, ROC-AUC: 0.8465\n",
      "\n",
      "=== Fold 2 ===\n",
      "Outcome ADHD -> F1: 0.8146, ROC-AUC: 0.8465\n",
      "\n",
      "=== Fold 2 ===\n",
      "Sex_F -> F1: 0.4946, ROC-AUC: 0.5423\n",
      "Sex_F -> F1: 0.4946, ROC-AUC: 0.5423\n",
      "Outcome ADHD -> F1: 0.8117, ROC-AUC: 0.8256\n",
      "\n",
      "=== Fold 3 ===\n",
      "Outcome ADHD -> F1: 0.8117, ROC-AUC: 0.8256\n",
      "\n",
      "=== Fold 3 ===\n",
      "Sex_F -> F1: 0.5357, ROC-AUC: 0.6349\n",
      "Sex_F -> F1: 0.5357, ROC-AUC: 0.6349\n",
      "Outcome ADHD -> F1: 0.8117, ROC-AUC: 0.7383\n",
      "\n",
      "=== Fold 4 ===\n",
      "Outcome ADHD -> F1: 0.8117, ROC-AUC: 0.7383\n",
      "\n",
      "=== Fold 4 ===\n",
      "Sex_F -> F1: 0.5235, ROC-AUC: 0.6267\n",
      "Sex_F -> F1: 0.5235, ROC-AUC: 0.6267\n",
      "Outcome ADHD -> F1: 0.8137, ROC-AUC: 0.8133\n",
      "\n",
      "=== Fold 5 ===\n",
      "Outcome ADHD -> F1: 0.8137, ROC-AUC: 0.8133\n",
      "\n",
      "=== Fold 5 ===\n",
      "Sex_F -> F1: 0.4453, ROC-AUC: 0.4910\n",
      "Sex_F -> F1: 0.4453, ROC-AUC: 0.4910\n",
      "Outcome ADHD -> F1: 0.8137, ROC-AUC: 0.7506\n",
      "\n",
      "=== Fold 6 ===\n",
      "Outcome ADHD -> F1: 0.8137, ROC-AUC: 0.7506\n",
      "\n",
      "=== Fold 6 ===\n",
      "Sex_F -> F1: 0.5141, ROC-AUC: 0.6235\n",
      "Sex_F -> F1: 0.5141, ROC-AUC: 0.6235\n",
      "Outcome ADHD -> F1: 0.8146, ROC-AUC: 0.8409\n",
      "\n",
      "=== Fold 7 ===\n",
      "Outcome ADHD -> F1: 0.8146, ROC-AUC: 0.8409\n",
      "\n",
      "=== Fold 7 ===\n",
      "Sex_F -> F1: 0.5421, ROC-AUC: 0.6052\n",
      "Sex_F -> F1: 0.5421, ROC-AUC: 0.6052\n",
      "Outcome ADHD -> F1: 0.8117, ROC-AUC: 0.7670\n",
      "\n",
      "=== Fold 8 ===\n",
      "Outcome ADHD -> F1: 0.8117, ROC-AUC: 0.7670\n",
      "\n",
      "=== Fold 8 ===\n",
      "Sex_F -> F1: 0.4582, ROC-AUC: 0.4949\n",
      "Sex_F -> F1: 0.4582, ROC-AUC: 0.4949\n",
      "Outcome ADHD -> F1: 0.8117, ROC-AUC: 0.7899\n",
      "\n",
      "=== Fold 9 ===\n",
      "Outcome ADHD -> F1: 0.8117, ROC-AUC: 0.7899\n",
      "\n",
      "=== Fold 9 ===\n",
      "Sex_F -> F1: 0.5069, ROC-AUC: 0.5925\n",
      "Sex_F -> F1: 0.5069, ROC-AUC: 0.5925\n",
      "Outcome ADHD -> F1: 0.8137, ROC-AUC: 0.8331\n",
      "\n",
      "=== Fold 10 ===\n",
      "Outcome ADHD -> F1: 0.8137, ROC-AUC: 0.8331\n",
      "\n",
      "=== Fold 10 ===\n",
      "Sex_F -> F1: 0.5498, ROC-AUC: 0.5923\n",
      "Sex_F -> F1: 0.5498, ROC-AUC: 0.5923\n",
      "Outcome ADHD -> F1: 0.8137, ROC-AUC: 0.7471\n",
      "\n",
      "=== Fold 11 ===\n",
      "Outcome ADHD -> F1: 0.8137, ROC-AUC: 0.7471\n",
      "\n",
      "=== Fold 11 ===\n",
      "Sex_F -> F1: 0.5387, ROC-AUC: 0.5699\n",
      "Sex_F -> F1: 0.5387, ROC-AUC: 0.5699\n",
      "Outcome ADHD -> F1: 0.8146, ROC-AUC: 0.8301\n",
      "\n",
      "=== Fold 12 ===\n",
      "Outcome ADHD -> F1: 0.8146, ROC-AUC: 0.8301\n",
      "\n",
      "=== Fold 12 ===\n",
      "Sex_F -> F1: 0.4945, ROC-AUC: 0.5739\n",
      "Sex_F -> F1: 0.4945, ROC-AUC: 0.5739\n",
      "Outcome ADHD -> F1: 0.8117, ROC-AUC: 0.7464\n",
      "\n",
      "=== Fold 13 ===\n",
      "Outcome ADHD -> F1: 0.8117, ROC-AUC: 0.7464\n",
      "\n",
      "=== Fold 13 ===\n",
      "Sex_F -> F1: 0.4899, ROC-AUC: 0.6218\n",
      "Sex_F -> F1: 0.4899, ROC-AUC: 0.6218\n",
      "Outcome ADHD -> F1: 0.8117, ROC-AUC: 0.8686\n",
      "\n",
      "=== Fold 14 ===\n",
      "Outcome ADHD -> F1: 0.8117, ROC-AUC: 0.8686\n",
      "\n",
      "=== Fold 14 ===\n",
      "Sex_F -> F1: 0.5267, ROC-AUC: 0.5831\n",
      "Sex_F -> F1: 0.5267, ROC-AUC: 0.5831\n",
      "Outcome ADHD -> F1: 0.8137, ROC-AUC: 0.7793\n",
      "\n",
      "=== Fold 15 ===\n",
      "Outcome ADHD -> F1: 0.8137, ROC-AUC: 0.7793\n",
      "\n",
      "=== Fold 15 ===\n",
      "Sex_F -> F1: 0.5385, ROC-AUC: 0.5827\n",
      "Sex_F -> F1: 0.5385, ROC-AUC: 0.5827\n",
      "Outcome ADHD -> F1: 0.8137, ROC-AUC: 0.7505\n",
      "\n",
      "=== Fold 16 ===\n",
      "Outcome ADHD -> F1: 0.8137, ROC-AUC: 0.7505\n",
      "\n",
      "=== Fold 16 ===\n",
      "Sex_F -> F1: 0.4800, ROC-AUC: 0.5468\n",
      "Sex_F -> F1: 0.4800, ROC-AUC: 0.5468\n",
      "Outcome ADHD -> F1: 0.8146, ROC-AUC: 0.8086\n",
      "\n",
      "=== Fold 17 ===\n",
      "Outcome ADHD -> F1: 0.8146, ROC-AUC: 0.8086\n",
      "\n",
      "=== Fold 17 ===\n",
      "Sex_F -> F1: 0.5519, ROC-AUC: 0.6121\n",
      "Sex_F -> F1: 0.5519, ROC-AUC: 0.6121\n",
      "Outcome ADHD -> F1: 0.8117, ROC-AUC: 0.8109\n",
      "\n",
      "=== Fold 18 ===\n",
      "Outcome ADHD -> F1: 0.8117, ROC-AUC: 0.8109\n",
      "\n",
      "=== Fold 18 ===\n",
      "Sex_F -> F1: 0.5053, ROC-AUC: 0.5900\n",
      "Sex_F -> F1: 0.5053, ROC-AUC: 0.5900\n",
      "Outcome ADHD -> F1: 0.8117, ROC-AUC: 0.8111\n",
      "\n",
      "=== Fold 19 ===\n",
      "Outcome ADHD -> F1: 0.8117, ROC-AUC: 0.8111\n",
      "\n",
      "=== Fold 19 ===\n",
      "Sex_F -> F1: 0.5221, ROC-AUC: 0.5454\n",
      "Sex_F -> F1: 0.5221, ROC-AUC: 0.5454\n",
      "Outcome ADHD -> F1: 0.8137, ROC-AUC: 0.7799\n",
      "\n",
      "=== Fold 20 ===\n",
      "Outcome ADHD -> F1: 0.8137, ROC-AUC: 0.7799\n",
      "\n",
      "=== Fold 20 ===\n",
      "Sex_F -> F1: 0.4710, ROC-AUC: 0.5705\n",
      "Sex_F -> F1: 0.4710, ROC-AUC: 0.5705\n",
      "Outcome ADHD -> F1: 0.8137, ROC-AUC: 0.7841\n",
      "\n",
      "=== Fold 21 ===\n",
      "Outcome ADHD -> F1: 0.8137, ROC-AUC: 0.7841\n",
      "\n",
      "=== Fold 21 ===\n",
      "Sex_F -> F1: 0.4892, ROC-AUC: 0.5992\n",
      "Sex_F -> F1: 0.4892, ROC-AUC: 0.5992\n",
      "Outcome ADHD -> F1: 0.8146, ROC-AUC: 0.8078\n",
      "\n",
      "=== Fold 22 ===\n",
      "Outcome ADHD -> F1: 0.8146, ROC-AUC: 0.8078\n",
      "\n",
      "=== Fold 22 ===\n",
      "Sex_F -> F1: 0.5126, ROC-AUC: 0.5315\n",
      "Sex_F -> F1: 0.5126, ROC-AUC: 0.5315\n",
      "Outcome ADHD -> F1: 0.8117, ROC-AUC: 0.8057\n",
      "\n",
      "=== Fold 23 ===\n",
      "Outcome ADHD -> F1: 0.8117, ROC-AUC: 0.8057\n",
      "\n",
      "=== Fold 23 ===\n",
      "Sex_F -> F1: 0.4982, ROC-AUC: 0.5935\n",
      "Sex_F -> F1: 0.4982, ROC-AUC: 0.5935\n",
      "Outcome ADHD -> F1: 0.8117, ROC-AUC: 0.7562\n",
      "\n",
      "=== Fold 24 ===\n",
      "Outcome ADHD -> F1: 0.8117, ROC-AUC: 0.7562\n",
      "\n",
      "=== Fold 24 ===\n",
      "Sex_F -> F1: 0.5395, ROC-AUC: 0.6367\n",
      "Sex_F -> F1: 0.5395, ROC-AUC: 0.6367\n",
      "Outcome ADHD -> F1: 0.8137, ROC-AUC: 0.8288\n",
      "\n",
      "=== Fold 25 ===\n",
      "Outcome ADHD -> F1: 0.8137, ROC-AUC: 0.8288\n",
      "\n",
      "=== Fold 25 ===\n",
      "Sex_F -> F1: 0.5055, ROC-AUC: 0.5378\n",
      "Sex_F -> F1: 0.5055, ROC-AUC: 0.5378\n",
      "Outcome ADHD -> F1: 0.8137, ROC-AUC: 0.8161\n",
      "\n",
      "=== CV Results ===\n",
      "Sex Mean roc auc Score: 0.5099\n",
      "Sex Mean F1: 0.5811\n",
      "ADHD Mean roc auc Score: 0.8131\n",
      "ADHD Mean F1: 0.7975\n",
      "Outcome ADHD -> F1: 0.8137, ROC-AUC: 0.8161\n",
      "\n",
      "=== CV Results ===\n",
      "Sex Mean roc auc Score: 0.5099\n",
      "Sex Mean F1: 0.5811\n",
      "ADHD Mean roc auc Score: 0.8131\n",
      "ADHD Mean F1: 0.7975\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Constants\n",
    "SEED = 42\n",
    "REPEATS = 5\n",
    "FOLDS = 5\n",
    "t_sex = 0.3\n",
    "t_adhd = 0.4\n",
    "\n",
    "# Evaluation function\n",
    "def eval_metrics(y_true, y_pred, weights, label=\"None\", thresh=0.3):\n",
    "    \"\"\"Evaluate predictions using F1 Score and ROC-AUC.\"\"\"\n",
    "    roc_auc = roc_auc_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, (y_pred > thresh).astype(int), sample_weight=weights)\n",
    "    print(f\"{label} -> F1: {f1:.4f}, ROC-AUC: {roc_auc:.4f}\")\n",
    "    return f1, roc_auc\n",
    "\n",
    "# Initialize lists to store scores and out-of-fold predictions\n",
    "scores_sex = []\n",
    "scores_adhd = []\n",
    "sex_oof = np.zeros(len(y_sex))\n",
    "adhd_oof = np.zeros(len(y_adhd))\n",
    "\n",
    "# Cross-validation setup\n",
    "rskf = RepeatedStratifiedKFold(n_splits=FOLDS, n_repeats=REPEATS, random_state=SEED)\n",
    "skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "# Logistic RegressionCV parameters\n",
    "logreg_params = {\n",
    "    \"penalty\": \"l2\",\n",
    "    \"cv\": skf,\n",
    "    \"fit_intercept\": True,\n",
    "    \"scoring\": \"f1\",\n",
    "    \"random_state\": SEED,\n",
    "    \"solver\": \"saga\"\n",
    "}\n",
    "\n",
    "model_sex = LogisticRegressionCV(**logreg_params)\n",
    "model_adhd = LogisticRegressionCV(**logreg_params)\n",
    "\n",
    "# Start cross-validation loop\n",
    "for fold, (train_idx, val_idx) in enumerate(rskf.split(train_adhd, y_adhd), 1):\n",
    "    print(f\"\\n=== Fold {fold} ===\")\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_val = train_adhd.iloc[train_idx].copy(), train_adhd.iloc[val_idx].copy()\n",
    "    y_train_sex, y_val_sex = y_sex.iloc[train_idx], y_sex.iloc[val_idx]\n",
    "    y_train_adhd, y_val_adhd = y_adhd.iloc[train_idx], y_adhd.iloc[val_idx]\n",
    "\n",
    "    # Sample weights\n",
    "    weights_train = np.where(y_train_adhd == \"11\", 2, 1)  # Assign higher weight to ADHD positive samples\n",
    "    weights_val = np.where(y_val_adhd == \"11\", 2, 1)  # Assign higher weight to ADHD positive samples\n",
    "\n",
    "    # Train model to predict Sex_F\n",
    "    model_sex.fit(X_train, y_train_sex, sample_weight=weights_train)\n",
    "    sex_train_pred = model_sex.predict_proba(X_train)[:, 1]\n",
    "    sex_val_pred = model_sex.predict_proba(X_val)[:, 1]\n",
    "    sex_oof[val_idx] += sex_val_pred / REPEATS\n",
    "\n",
    "    sex_f1, sex_roc_auc = eval_metrics(y_val_sex, sex_val_pred, weights_val, \"Sex_F\", thresh=t_sex)\n",
    "    scores_sex.append((sex_f1, sex_roc_auc))\n",
    "\n",
    "    # Add predicted sex probabilities\n",
    "    X_train = X_train.assign(sex_proba=sex_train_pred)\n",
    "    X_val = X_val.assign(sex_proba=sex_val_pred)\n",
    "\n",
    "    # Create interaction features\n",
    "    for col in interactions:\n",
    "        X_train[f\"I_{col}\"] = X_train[col] * X_train[\"sex_proba\"]\n",
    "        X_val[f\"I_{col}\"] = X_val[col] * X_val[\"sex_proba\"]\n",
    "\n",
    "    # Train model to predict ADHD outcome\n",
    "    model_adhd.fit(X_train[features_adhd], y_train_adhd, sample_weight=weights_train)\n",
    "    adhd_val_pred = model_adhd.predict_proba(X_val[features_adhd])[:, 1]\n",
    "    adhd_oof[val_idx] += adhd_val_pred / REPEATS\n",
    "\n",
    "    adhd_f1, adhd_roc_auc = eval_metrics(y_val_adhd, adhd_val_pred, weights_val, \"Outcome ADHD\", thresh=t_adhd)\n",
    "    scores_adhd.append((adhd_f1, adhd_roc_auc))\n",
    "\n",
    "# Print final results\n",
    "print(f\"\\n=== CV Results ===\")\n",
    "print(f\"Sex Mean roc auc Score: {np.mean([b for b, _ in scores_sex]):.4f}\")\n",
    "print(f\"Sex Mean F1: {np.mean([f for _, f in scores_sex]):.4f}\")\n",
    "print(f\"ADHD Mean roc auc Score: {np.mean([b for b, _ in scores_adhd]):.4f}\")\n",
    "print(f\"ADHD Mean F1: {np.mean([f for _, f in scores_adhd]):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86c63ce",
   "metadata": {},
   "source": [
    "## only features_adhd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f517c6e1",
   "metadata": {},
   "source": [
    "I tried it using only the features that I thought were important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb01474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1 ===\n",
      "F1 Score: 0.8498, Brier Score: 0.2172\n",
      "\n",
      "=== Fold 2 ===\n",
      "F1 Score: 0.8498, Brier Score: 0.2172\n",
      "\n",
      "=== Fold 2 ===\n",
      "F1 Score: 0.8469, Brier Score: 0.2192\n",
      "\n",
      "=== Fold 3 ===\n",
      "F1 Score: 0.8469, Brier Score: 0.2192\n",
      "\n",
      "=== Fold 3 ===\n",
      "F1 Score: 0.8481, Brier Score: 0.2192\n",
      "\n",
      "=== Fold 4 ===\n",
      "F1 Score: 0.8481, Brier Score: 0.2192\n",
      "\n",
      "=== Fold 4 ===\n",
      "F1 Score: 0.8527, Brier Score: 0.2177\n",
      "\n",
      "=== Fold 5 ===\n",
      "F1 Score: 0.8527, Brier Score: 0.2177\n",
      "\n",
      "=== Fold 5 ===\n",
      "F1 Score: 0.8516, Brier Score: 0.2177\n",
      "\n",
      "=== Final Evaluation ===\n",
      "Mean F1: 0.8498\n",
      "Std F1: 0.0021\n",
      "Mean Brier: 0.2182\n",
      "Std Brier: 0.0008\n",
      "F1 Score: 0.8516, Brier Score: 0.2177\n",
      "\n",
      "=== Final Evaluation ===\n",
      "Mean F1: 0.8498\n",
      "Std F1: 0.0021\n",
      "Mean Brier: 0.2182\n",
      "Std Brier: 0.0008\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import brier_score_loss, f1_score\n",
    "import numpy as np\n",
    "\n",
    "FOLDS = 5\n",
    "SEED = 42\n",
    "\n",
    "# Initialize storage\n",
    "scores_f1 = []\n",
    "scores_brier = []\n",
    "\n",
    "# Store OOF predictions\n",
    "adhd_oof = np.zeros(len(y_adhd))\n",
    "\n",
    "# Classification threshold\n",
    "t_adhd = 0.4\n",
    "\n",
    "# Stratified K-Fold\n",
    "skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "params = {\n",
    "    \"penalty\": \"l1\",\n",
    "    \"cv\": skf,\n",
    "    \"fit_intercept\": True,\n",
    "    \"scoring\": \"f1\",\n",
    "    \"random_state\": SEED,\n",
    "    \"solver\": \"saga\"\n",
    "    }\n",
    "\n",
    "model = LogisticRegressionCV(**params)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_adhd, y_adhd), 1):\n",
    "    print(f\"\\n=== Fold {fold} ===\")\n",
    "\n",
    "    # Data split\n",
    "    X_train, X_val = train_adhd.iloc[train_idx], train_adhd.iloc[val_idx]\n",
    "    y_train = y_adhd.iloc[train_idx]\n",
    "    y_val = y_adhd.iloc[val_idx]\n",
    "    \n",
    "    # Sample weights as in the first script\n",
    "    weights_train = ((y_sex.iloc[train_idx] == 1) & (y_train == 1)).astype(int) + 1\n",
    "    weights_val = ((y_sex.iloc[val_idx] == 1) & (y_val == 1)).astype(int) + 1\n",
    "\n",
    "    # Column check\n",
    "    missing = [col for col in features_adhd if col not in X_train.columns]\n",
    "    if missing:\n",
    "        print(f\"Missing columns: {missing}\")\n",
    "    features_adhd_valid = [col for col in features_adhd if col in X_train.columns]\n",
    "\n",
    "    # Fit and predict\n",
    "    model.fit(X_train[features_adhd_valid], y_train, sample_weight=weights_train)\n",
    "    pred_proba = model.predict_proba(X_val[features_adhd_valid])[:, 1]\n",
    "    adhd_oof[val_idx] = pred_proba\n",
    "\n",
    "    # Calculate scores\n",
    "    brier = brier_score_loss(y_val, pred_proba)\n",
    "    f1 = f1_score(y_val, (pred_proba > t_adhd).astype(int), sample_weight=weights_val)\n",
    "\n",
    "    print(f\"F1 Score: {f1:.4f}, Brier Score: {brier:.4f}\")\n",
    "\n",
    "    scores_f1.append(f1)\n",
    "    scores_brier.append(brier)\n",
    "\n",
    "# ===== Results Summary =====\n",
    "\n",
    "scores_f1 = np.array(scores_f1)\n",
    "scores_brier = np.array(scores_brier)\n",
    "\n",
    "print(\"\\n=== Final Evaluation ===\")\n",
    "print(f\"Mean F1: {scores_f1.mean():.4f}\")\n",
    "print(f\"Std F1: {scores_f1.std():.4f}\")\n",
    "print(f\"Mean Brier: {scores_brier.mean():.4f}\")\n",
    "print(f\"Std Brier: {scores_brier.std():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ed3862",
   "metadata": {},
   "source": [
    "## all adhd data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057ea148",
   "metadata": {},
   "source": [
    "Here are all the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd08e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1 ===\n",
      "F1 Score: 0.8498, Brier Score: 0.2172\n",
      "\n",
      "=== Fold 2 ===\n",
      "F1 Score: 0.8498, Brier Score: 0.2172\n",
      "\n",
      "=== Fold 2 ===\n",
      "F1 Score: 0.8469, Brier Score: 0.1961\n",
      "\n",
      "=== Fold 3 ===\n",
      "F1 Score: 0.8469, Brier Score: 0.1961\n",
      "\n",
      "=== Fold 3 ===\n",
      "F1 Score: 0.8481, Brier Score: 0.2192\n",
      "\n",
      "=== Fold 4 ===\n",
      "F1 Score: 0.8481, Brier Score: 0.2192\n",
      "\n",
      "=== Fold 4 ===\n",
      "F1 Score: 0.8527, Brier Score: 0.2177\n",
      "\n",
      "=== Fold 5 ===\n",
      "F1 Score: 0.8527, Brier Score: 0.2177\n",
      "\n",
      "=== Fold 5 ===\n",
      "F1 Score: 0.8516, Brier Score: 0.2177\n",
      "\n",
      "=== Final Evaluation ===\n",
      "Mean F1: 0.8498\n",
      "Std F1: 0.0021\n",
      "Mean Brier: 0.2136\n",
      "Std Brier: 0.0088\n",
      "F1 Score: 0.8516, Brier Score: 0.2177\n",
      "\n",
      "=== Final Evaluation ===\n",
      "Mean F1: 0.8498\n",
      "Std F1: 0.0021\n",
      "Mean Brier: 0.2136\n",
      "Std Brier: 0.0088\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import brier_score_loss, f1_score\n",
    "import numpy as np\n",
    "\n",
    "FOLDS = 5\n",
    "SEED = 42\n",
    "\n",
    "# Initialize storage\n",
    "scores_f1 = []\n",
    "scores_brier = []\n",
    "\n",
    "# Store OOF predictions\n",
    "adhd_oof = np.zeros(len(y_adhd))\n",
    "\n",
    "# Classification threshold\n",
    "t_adhd = 0.4\n",
    "\n",
    "# Stratified K-Fold\n",
    "skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "params = {\n",
    "    \"penalty\": \"l1\",\n",
    "    \"cv\": skf,\n",
    "    \"fit_intercept\": True,\n",
    "    \"scoring\": \"f1\",\n",
    "    \"random_state\": SEED,\n",
    "    \"solver\": \"saga\"\n",
    "}\n",
    "\n",
    "model = LogisticRegressionCV(**params)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_adhd, y_adhd), 1):\n",
    "    print(f\"\\n=== Fold {fold} ===\")\n",
    "\n",
    "    # Data split\n",
    "    X_train, X_val = train_adhd.iloc[train_idx], train_adhd.iloc[val_idx]\n",
    "    y_train = y_adhd.iloc[train_idx]\n",
    "    y_val = y_adhd.iloc[val_idx]\n",
    "    \n",
    "    # Sample weights as in the first script\n",
    "    weights_train = ((y_sex.iloc[train_idx] == 1) & (y_train == 1)).astype(int) + 1\n",
    "    weights_val = ((y_sex.iloc[val_idx] == 1) & (y_val == 1)).astype(int) + 1\n",
    "\n",
    "    \n",
    "    # Fit and predict\n",
    "    model.fit(X_train, y_train, sample_weight=weights_train)\n",
    "    pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "    adhd_oof[val_idx] = pred_proba\n",
    "\n",
    "    # Calculate scores\n",
    "    brier = brier_score_loss(y_val, pred_proba)\n",
    "    f1 = f1_score(y_val, (pred_proba > t_adhd).astype(int), sample_weight=weights_val)\n",
    "\n",
    "    print(f\"F1 Score: {f1:.4f}, Brier Score: {brier:.4f}\")\n",
    "\n",
    "    scores_f1.append(f1)\n",
    "    scores_brier.append(brier)\n",
    "\n",
    "# ===== Results Summary =====\n",
    "\n",
    "scores_f1 = np.array(scores_f1)\n",
    "scores_brier = np.array(scores_brier)\n",
    "\n",
    "print(\"\\n=== Final Evaluation ===\")\n",
    "print(f\"Mean F1: {scores_f1.mean():.4f}\")\n",
    "print(f\"Std F1: {scores_f1.std():.4f}\")\n",
    "print(f\"Mean Brier: {scores_brier.mean():.4f}\")\n",
    "print(f\"Std Brier: {scores_brier.std():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2867d2b8",
   "metadata": {},
   "source": [
    "## prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e84eedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_adhd = test[features_adhd]\n",
    "test_sex = test[important_features_sex]\n",
    "# Drop only the columns from `trf` that are present in `train`\n",
    "columns_to_drop = [col for col in trf.columns if col in test.columns]\n",
    "test_adhd = train.drop(columns=columns_to_drop)\n",
    "\n",
    "# Drop the target columns\n",
    "test_adhd = test_adhd.drop(columns=target_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbcb1e8",
   "metadata": {},
   "source": [
    "## Submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd3a466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file for Sex created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Ensure all arrays have the same length\n",
    "if len(test_ids) == len(sex_pred_binary):\n",
    "    # Create a DataFrame for submission\n",
    "    submission = pd.DataFrame({\n",
    "        'participant_id': test_ids,\n",
    "         'ADHD_Outcome' : adhd_pred_binary ,\n",
    "        'Sex_F': sex_pred_binary  \n",
    "    })\n",
    "\n",
    "    # Save the submission file\n",
    "    submission.to_csv('submission_Sex_0.7416_adhd_0.76417.csv', index=False)\n",
    "    print(\"Submission file for Sex created successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
